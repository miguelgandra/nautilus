#######################################################################################################
# Check and Handle Outliers in Position Estimates ##########################$##########################
#######################################################################################################

#' Flag and invalidate spurious FastLoc GPS positions from animal tracking data
#'
#' @description
#' Detects and removes implausible FastLoc GPS locations from animal tracking datasets
#' generated by Wildlife Computers tags.
#'
#' @details
#' The function supports two types of position data:
#' \itemize{
#'   \item \code{"FastGPS"}: automatically acquired positions from the tag
#'   \item \code{"User"}: manually added positions through the Wildlife Computers Data Portal
#' }
#'
#' Implausible positions are identified based on the following validation checks:
#' \enumerate{
#'   \item \strong{Speed Filtering}: Detects and removes locations that imply unrealistic movement speeds,
#'         based on a user-defined maximum threshold (`max.speed.kmh`). The function operates iteratively:
#'         it recalculates step speeds after each removal and continues until all remaining speeds are plausible
#'         or a maximum number of iterations is reached. When a speed violation is detected, hierarchical clustering
#'         is applied to the spatial coordinates of neighboring detections to identify and remove the most likely outlier
#'         responsible for the overspeed.
#'
#'   \item \strong{Distance Check}: Flags positions that are located farther than a specified radius from the
#'         deployment location (`max.distance.km`). This is useful for identifying early detections that may be erroneous
#'         or not biologically plausible based on known release location.
#'
#'   \item \strong{Quality Control}: Optionally removes positions with low location quality, based on the number of
#'         satellites used in the FastLoc GPS fix (`min.satellites`). Positions with fewer satellites than the threshold
#'         are considered less reliable and can be excluded.
#' }
#'
#' The function also checks for inconsistencies between "User" positions and the deployment location
#' provided in the metadata.
#'
#' All flagged positions are set to \code{NA}, and diagnostic plots are generated
#' to support visual inspection of the filtering process.
#'
#'
#' @param data A list of data frames/tables or a single data frame containing tracking data.
#' @param id.metadata A data frame containing deployment information for each individual.
#' @param id.col Character string specifying the column name containing animal IDs (default: "ID").
#' @param datetime.col Character string specifying the datetime column (default: "datetime").
#' @param position.type.col Character string specifying the position type column (default: "position_type").
#' @param lon.col Character string specifying the longitude column (default: "lon").
#' @param lat.col Character string specifying the latitude column (default: "lat").
#' @param deploy.lon.col Character string specifying the deployment longitude column in metadata (default: "deploy_lon").
#' @param deploy.lat.col Character string specifying the deployment latitude column in metadata (default: "deploy_lat").
#' @param quality.col Character string specifying the quality/satellite count column (default: "quality").
#' @param max.speed.kmh Numeric, maximum allowed speed between consecutive positions (km/h). If NULL, skips speed filtering.
#' @param max.distance.km Numeric, maximum allowed distance from deployment location (km, default: 100).
#' @param min.satellites Integer, minimum number of satellites required for valid FastLoc positions (optional).
#' @param plot Logical, whether to generate diagnostic plots (default: TRUE).
#'
#' @return Returns a list of filtered data frames/tables (matching input structure) with:
#' \itemize{
#'   \item Implausible positions set to NA (lon/lat/position_type/quality)
#'   \item User positions always preserved
#'   \item Summary statistics printed to console
#' }
#'
#' @export


filterLocations <- function(data,
                            id.metadata,
                            id.col = "ID",
                            datetime.col = "datetime",
                            position.type.col = "position_type",
                            lon.col = "lon",
                            lat.col = "lat",
                            deploy.lon.col = "deploy_lon",
                            deploy.lat.col = "deploy_lat",
                            quality.col = "quality",
                            max.speed.kmh = NULL,
                            max.distance.km = 100,
                            min.satellites = NULL,
                            plot = TRUE) {


  ##############################################################################
  # Input validation ###########################################################
  ##############################################################################

  # start the timer
  start.time <- Sys.time()

  # if 'data' is not a list, split it into a list of individual data sets based on 'id.col'
  if (!is.list(data)) {
    data <- split(data, f = data[[id.col]])
  }

  # check if the 'geosphere' package is installed.
  if(!requireNamespace("geosphere", quietly=TRUE)) stop("The 'geosphere' package is required but is not installed. Please install 'geosphere' using install.packages('geosphere') and try again.", call. = FALSE)

  # check if specified columns exist in the data
  if(!id.col %in% names(data[[1]])) stop(paste0("The specified id.col ('", id.col, "') was not found in the supplied data."), call. = FALSE)
  if(!datetime.col %in% names(data[[1]])) stop(paste0("The specified datetime.col ('", datetime.col, "') was not found in the supplied data."), call. = FALSE)
  if(!position.type.col %in% names(data[[1]])) stop(paste0("The specified position.type.col ('", position.type.col, "') was not found in the supplied data."), call. = FALSE)
  if(!lon.col %in% names(data[[1]])) stop(paste0("The specified lon.col ('", lon.col, "') was not found in the supplied data."), call. = FALSE)
  if(!lat.col %in% names(data[[1]])) stop(paste0("The specified lat.col ('", lat.col, "') was not found in the supplied data."), call. = FALSE)
  if(!quality.col %in% names(data[[1]])) stop(paste0("The specified quality.col ('", quality.col, "') was not found in the supplied data."), call. = FALSE)

  # check if deployment coordinate columns exist in metadata
  if(!deploy.lon.col %in% names(id.metadata)) stop(paste0("The specified deploy.lon.col ('", deploy.lon.col, "') was not found in id.metadata."), call. = FALSE)
  if(!deploy.lat.col %in% names(id.metadata)) stop(paste0("The specified deploy.lat.col ('", deploy.lat.col, "') was not found in id.metadata."), call. = FALSE)

  # ensure datetime column is of POSIXct class
  if (!inherits(data[[1]][[datetime.col]], "POSIXct")) {
    stop(sprintf("The '%s' column must be of class 'Date' or 'POSIXct'.", datetime.col))
  }

  # check if all data elements are either a data.frame or data.table
  any_invalid <- any(sapply(data, function(x) {!is.null(x) && !inherits(x, "data.frame") && !inherits(x, "data.table")}))
  if (any_invalid) {
    stop("All non-NULL elements of 'data_list' must be of class 'data.frame' or 'data.table'.", call. = FALSE)
  }

  # validate map plotting  packages
  if (plot) {
    required_pkgs <- c("maps", "mapdata", "prettymapr")
    missing_pkgs <- required_pkgs[!sapply(required_pkgs, requireNamespace, quietly = TRUE)]
    if (length(missing_pkgs) > 0) {
      # base message components
      pkg_list <- paste(missing_pkgs, collapse = ", ")
      install_cmd <- paste0("install.packages(c('", paste(missing_pkgs, collapse = "', '"), "'))")
      # build the message parts with proper wrapping
      width <- getOption("width")
      main_msg <- paste(strwrap(
        sprintf("The following package%s required for diagnostic plots %s missing: %s",
                ifelse(length(missing_pkgs) > 1, "s are", " is"),
                ifelse(length(missing_pkgs) > 1, "are", "is"),
                pkg_list),
        width = width), collapse = "\n")
      options_msg <- paste(
        "You have two options:",
        paste0("1. ", paste(strwrap(
          paste("Install with:", install_cmd),
          width = width - 3,  # Account for bullet point spacing
          exdent = 3
        ), collapse = "\n   ")),
        paste0("2. ", paste(strwrap(
          "Set plot = FALSE to skip visualization",
          width = width - 3,
          exdent = 3
        ), collapse = "\n   ")),
        sep = "\n")
      # combine all parts
      full_msg <- paste(main_msg, options_msg, sep = "\n\n")
      stop(full_msg, call. = FALSE)
    }

    # cache the map data to speed up plotting
    library(mapdata)
    .worldHires_cache <- maps::map("worldHires", plot = FALSE, fill = TRUE)
  }


  ##############################################################################
  # Process each data element ##################################################
  ##############################################################################

  # get the total number of animals in the dataset
  n_animals <- length(data)

  # feedback message for the user
  cat(paste0(
    crayon::bold("\n================ Filtering Position Estimates ================\n"),
    "Analyzing locations for ", n_animals, " ", ifelse(n_animals == 1, "tag", "tags"), " to ensure data integrity\n",
    crayon::bold("==============================================================\n\n")
  ))


  # iterate over each element in 'data'
  for (i in 1:length(data)) {

    # access the individual dataset
    dt <- data.table::copy(data[[i]])

    # convert to data.table for efficient processing
    if (!is.data.table(dt)) setDT(dt)

    # retrieve ID from the dataset based on the specified 'id.col' column
    id <- unique(dt[[id.col]])

    # skip NULL or empty elements in the list
    if (is.null(dt) || length(dt) == 0) next

    # skip if no position data exists
    if(all(is.na(dt[[position.type.col]]))) next

    # order by datetime
    setorderv(dt, datetime.col)

    # get first user position with valid coordinates
    user_pos <- dt[get(position.type.col) == "User" & !is.na(get(lon.col)) & !is.na(get(lat.col)),
                   .(lon = get(lon.col)[1], lat = get(lat.col)[1])]

    # check metadata for deployment coordinates
    metadata_row <- id.metadata[id.metadata[[id.col]] == id, ]
    metadata_pos <- NULL
    if (nrow(metadata_row) > 0) {
      deploy_lon <- metadata_row[[deploy.lon.col]][1]
      deploy_lat <- metadata_row[[deploy.lat.col]][1]
      if (!is.na(deploy_lon) && !is.na(deploy_lat)) {
        metadata_pos <- data.table(lon = deploy_lon, lat = deploy_lat)
      }
    }

    # determine deployment position
    warning_msg <- c()
    if (nrow(user_pos) > 0) {
      deploy_pos <- user_pos
      # compare with metadata (if available)
      if (!is.null(metadata_pos)) {
        dist <- geosphere::distHaversine(as.numeric(user_pos), as.numeric(metadata_pos)) / 1000
        if (dist > 1) warning_msg <- sprintf("First user position differs from metadata by %.2f km", dist)
      }
    } else if (!is.null(metadata_pos)) {
      deploy_pos <- metadata_pos
    } else {
      warning_msg <- sprintf("No valid user positions or metadata coordinates available.", id)
    }

    # count total positions
    total_pos <- sum(!is.na(dt[[position.type.col]]), na.rm = TRUE)
    total_user <- sum(dt[[position.type.col]] == "User", na.rm = TRUE)
    total_fastloc <- sum(dt[[position.type.col]] == "FastGPS", na.rm = TRUE)

    # initialize flag counters
    flag_counts <- list(satellite = 0, distance = 0, speed = 0)


    ############################################################################
    # Initial filtering based on satellite count

    if (!is.null(min.satellites)) {
      invalid_sat <- which(dt[[position.type.col]] == "FastGPS" & !is.na(dt[[quality.col]]) & dt[[quality.col]] < min.satellites)
      flag_counts$satellite <- length(invalid_sat)
      if (length(invalid_sat) > 0) {
        dt[invalid_sat, c(position.type.col, lon.col, lat.col, quality.col) := NA]
      }
    }


    ############################################################################
    # Distance-based filtering #################################################

    # if no deployment position found, skip distance filtering
    if(nrow(deploy_pos) == 0) {
      warning("No deployment position found for ", id, ". Skipping distance filtering.")
    } else {
      # calculate distance from deployment for all positions (in km)
      distances <- geosphere::distGeo(cbind(dt[[lon.col]], dt[[lat.col]]), cbind(deploy_pos[[lon.col]], deploy_pos[[lat.col]])) / 1000
      # identify spurious distances
      invalid_dist <- which(dt[[position.type.col]] == "FastGPS" & distances > max.distance.km & !is.na(dt[[position.type.col]]))
      flag_counts$distance <- length(invalid_dist)
      if (length(invalid_dist) > 0) {
        dt[invalid_dist, c(position.type.col, lon.col, lat.col, quality.col) := NA]
      }
    }


    ############################################################################
    # Speed-based filtering ####################################################

    if (!is.null(max.speed.kmh)) {
      # initialize counters
      iteration <- 0
      max_iterations <- 10
      total_removed <- 0

      # get indices of all valid positions (both User and FastGPS)
      position_idx <- which(!is.na(dt[[lon.col]]) & !is.na(dt[[lat.col]]))

      # only proceed if there are enough positions to check
      if (length(position_idx) > 1) {
        repeat {

          # increase counter and set changed flag
          iteration <- iteration + 1
          changed <- FALSE

          # order by datetime (important!)
          position_idx <- position_idx[order(dt[[datetime.col]][position_idx])]

          # calculate time differences (in hours)
          times <- dt[[datetime.col]][position_idx]
          time_diffs <- as.numeric(difftime(times[-1], times[-length(times)]), units = "hours")

          # calculate distances between consecutive points (in km)
          lons <- dt[[lon.col]][position_idx]
          lats <- dt[[lat.col]][position_idx]
          distances <- geosphere::distGeo(
            cbind(lons[-length(lons)], lats[-length(lats)]),
            cbind(lons[-1], lats[-1])) / 1000

          # calculate speeds in km/h
          speeds <- distances / time_diffs

          # identify pairs where speed exceeds threshold (only consider pairs involving FastGPS)
          speed_violations <- which(speeds > max.speed.kmh &
                                      (dt[[position.type.col]][position_idx[-length(position_idx)]] == "FastGPS" |
                                         dt[[position.type.col]][position_idx[-1]] == "FastGPS"))

          # exit loop if no more violations found or max iterations reached
          if (length(speed_violations) == 0 || iteration > max_iterations) break

          # for each violation, apply hierarchical clustering to identify outlier
          to_remove <- c()
          for (j in speed_violations) {
            # get indices of the current pair and surrounding points (window of 5 points)
            window_start <- max(1, j-2)
            window_end <- min(length(position_idx), j+2)
            window_idx <- position_idx[window_start:window_end]

            # extract coordinates for clustering
            coords <- cbind(dt[[lon.col]][window_idx], dt[[lat.col]][window_idx])

            # calculate distance matrix
            dist_matrix <- dist(coords)

            # perform hierarchical clustering
            hc <- hclust(dist_matrix)

            # cut tree into 2 clusters
            clusters <- cutree(hc, k = 2)

            # identify the smaller cluster as potential outliers
            cluster_counts <- table(clusters)
            outlier_cluster <- as.numeric(names(cluster_counts)[which.min(cluster_counts)])

            # get the index of the outlier in the original data
            outlier_pos <- which(clusters == outlier_cluster)
            outlier_candidates <- window_idx[outlier_pos]

            # only consider FastGPS positions for removal
            fastloc_outliers <- outlier_candidates[dt[[position.type.col]][outlier_candidates] == "FastGPS"]

            # if we found FastGPS outliers, select the one with worst quality (or first if equal)
            if (length(fastloc_outliers) > 0) {
              if (!is.null(quality.col) && all(!is.na(dt[[quality.col]][fastloc_outliers]))) {
                # remove the one with lowest quality
                to_remove <- c(to_remove, fastloc_outliers[which.min(dt[[quality.col]][fastloc_outliers])])
              } else {
                # default to removing the first one if no quality info
                to_remove <- c(to_remove, fastloc_outliers[1])
              }
            }
          }

          # remove the selected points (only unique indices)
          to_remove <- unique(to_remove)
          if (length(to_remove) > 0) {
            dt[to_remove, c(position.type.col, lon.col, lat.col, quality.col) := NA]
            total_removed <- total_removed + length(to_remove)
            position_idx <- setdiff(position_idx, to_remove)
            changed <- TRUE
          }

          # exit conditions
          if (!changed || iteration >= max_iterations) break
        }

        # update flag counts
        flag_counts$speed <- total_removed
      }
    }


    ############################################################################
    # Print info to console ####################################################

    # print summary
    total_flags <- sum(unlist(flag_counts))
    status_color <- if (total_flags == 0 & length(warning_msg)==0) crayon::blue$bold else crayon::red$bold
    cat(status_color("ID:", id, "\n"))
    cat(sprintf("Total positions: %d [User: %d, Fastloc: %d]\n", total_pos, total_user, total_fastloc))
    if(total_flags == 0 & length(warning_msg)==0){
      cat("\u2713 All positions meet quality standards\n")
    }else{
      if(length(warning_msg)>0) {
        cat("Warning:", warning_msg, "\n")
      }
      if (total_flags > 0) {
        if (flag_counts$satellite > 0) cat(sprintf("\u2717 %d flagged position%s with <%d satellites\n", flag_counts$satellite, ifelse(flag_counts$satellite == 1, "", "s"), min.satellites))
        if (flag_counts$distance > 0) cat(sprintf("\u2717 %d flagged position%s >%.1f km from deployment\n", flag_counts$distance, ifelse(flag_counts$distance == 1, "", "s"), max.distance.km))
        if (flag_counts$speed > 0){
          cat(sprintf("\u2717 %d position%s implying speed >%.1f km/h (%d iteration%s)\n",
                      flag_counts$speed,
                      ifelse(flag_counts$speed == 1, "", "s"),
                      max.speed.kmh,
                      iteration-1,
                      ifelse(iteration-1 == 1, "", "s")))
        }
      }
    }
    cat("\n")


    ############################################################################
    # Diagnostic plots #########################################################

    if (plot && (total_flags>0 | length(warning_msg)>0)) {

      # get row indices with valid locations
      location_rows <- which(!is.na(data[[i]][[lon.col]]) & !is.na(data[[i]][[lat.col]]))

      # prepare data for plotting
      orig_lon <- data[[i]][[lon.col]][location_rows]
      orig_lat <- data[[i]][[lat.col]][location_rows]
      new_lon <- dt[[lon.col]][location_rows]
      new_lat <- dt[[lat.col]][location_rows]
      pos_type <- data[[i]][[position.type.col]][location_rows]

      # determine if we need to show both deployment markers
      show_both_deployments <- length(warning_msg) > 0 && nrow(user_pos) > 0 && !is.null(metadata_pos)

      # calculate ranges including relevant deployment locations
      range_lons <- c(orig_lon, new_lon)
      range_lats <- c(orig_lat, new_lat)
      if (show_both_deployments) {
        range_lons <- c(range_lons, user_pos$lon, metadata_pos$lon)
        range_lats <- c(range_lats, user_pos$lat, metadata_pos$lat)
      } else if (nrow(user_pos) > 0) {
        range_lons <- c(range_lons, user_pos$lon)
        range_lats <- c(range_lats, user_pos$lat)
      } else if (!is.null(metadata_pos)) {
        range_lons <- c(range_lons, metadata_pos$lon)
        range_lats <- c(range_lats, metadata_pos$lat)
      }
      lon_range <- extendrange(na.omit(range_lons), f = 0.2)
      lat_range <- extendrange(na.omit(range_lats), f = 0.2)

      # force equal aspect ratio
      max_range <- max(diff(lon_range), diff(lat_range))/2
      lon_mid <- mean(lon_range)
      lat_mid <- mean(lat_range)
      lon_range <- c(lon_mid - max_range, lon_mid + max_range)
      lat_range <- c(lat_mid - max_range, lat_mid + max_range)

      # adjust margins
      par(mar = c(4, 4.5, 3.5, 6), mgp = c(2.3, 0.7, 0))

      # initialize plot with formatted axes
      plot(NA, xlim = lon_range, ylim = lat_range, asp = 1, las = 1, axes = FALSE,
           xlab = "", ylab = "", xaxs = "i", yaxs = "i")

      # add title and axes labels
      title(main = paste(id, "- Positions"), line= 2, cex.main = 0.9)
      deploy_duration <- as.numeric(difftime(max(data[[i]][[datetime.col]]), min(data[[i]][[datetime.col]]), "hours"))
      title(main = sprintf("[Deployment: %.2f hours] ", deploy_duration), line = 0.9, font.main=1, cex.main = 0.8)
      title(xlab = "Longitude", line = 2.2, cex.lab = 0.9)
      title(ylab = "Latitude", line = 3.2, cex.lab = 0.9)

      # add background color
      rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4], col="#D6E6F2")

      # add custom axes with pretty labels
      axis(1, at = pretty(lon_range, n = 5), labels = sprintf("%.2f", pretty(lon_range, n = 5)), cex.axis = 0.9)
      axis(2, at = pretty(lat_range, n = 5), labels = sprintf("%.2f", pretty(lat_range, n = 5)), las=1, cex.axis = 0.9)

      # draw box
      box()

      # add world map background
      maps::map(.worldHires_cache, add = TRUE, col = "gray70", lwd=0.5, fill = TRUE)

      # set color palette
      color_pal <- adjustcolor(c("darkorchid", "maroon2", "blue", "red"), alpha.f=0.8)

      # plot deployment locations (order matters for visibility)
      if (show_both_deployments) {
        # case 1: both exist and mismatch - plot both with labels
        points(metadata_pos$lon, metadata_pos$lat, pch = 24, bg = color_pal[2],  lwd = 0.4, cex = 1.5)
        text(metadata_pos$lon, metadata_pos$lat,, labels = 1, col = "white", cex = 0.5, font = 2)
        points(user_pos$lon, user_pos$lat,  pch = 24, bg = color_pal[1], lwd = 0.4, cex = 1.5)
      } else if (nrow(user_pos) > 0) {
        # case 2: only user position exists or they match - plot user only
        points(user_pos$lon, user_pos$lat, pch = 24, bg = color_pal[1], lwd = 0.4, cex = 1.5)
      } else if (!is.null(metadata_pos)) {
        # case 3: only metadata exists - plot metadata only
        points(metadata_pos$lon, metadata_pos$lat, pch = 24, bg = color_pal[2],  lwd = 0.4, cex = 1.5)
        text(metadata_pos$lon, metadata_pos$lat,, labels = 1, col = "white", cex = 0.5, font = 2)
      }

      # plot valid positions
      fastloc_idx <- which(!is.na(orig_lon) & !is.na(new_lon) & pos_type != "User")
      points(new_lon[fastloc_idx], new_lat[fastloc_idx], bg = color_pal[3], pch = 21, lwd = 0.4, cex = 1.5)

      # plot removed positions
      removed_idx <- which(!is.na(orig_lon) & is.na(new_lon))
      points(orig_lon[removed_idx], orig_lat[removed_idx], bg = color_pal[4], pch = 21, lwd = 0.4, cex = 1.5)

      # add location numbers
      all_indices <- 1:length(orig_lon)
      text(orig_lon, orig_lat, labels = all_indices, col = "white", cex = 0.5, font = 2)

      # build legend
      legend_labels <- c()
      legend_colors <- c()
      legend_pch <- c()

      # add deployment marker to legend if shown
      if (show_both_deployments) {
        legend_labels <- c("User", "Metadata")
        legend_colors <- color_pal[1:2]
        legend_pch <- c(24, 24)
      } else if (nrow(user_pos) > 0) {
        legend_labels <- "User"
        legend_colors <- color_pal[1]
        legend_pch <- 24
      } else if (!is.null(metadata_pos)) {
        legend_labels <- "Metadata"
        legend_colors <- color_pal[2]
        legend_pch <- 24
      }

      # add regular positions to legend
      legend_labels <- c(
        sprintf("%s (n=%d)", legend_labels, sum(pos_type == "User", na.rm = TRUE)),
        sprintf("Fastloc (n=%d)", sum(!is.na(new_lon) & pos_type != "User")),
        sprintf("Removed (n=%d)", length(removed_idx)))
      legend_colors <- c(legend_colors, color_pal[3], color_pal[4])
      legend_pch <- c(legend_pch, 21, 21)

      # draw legend
      legend("right", inset = c(-0.28, 0),
             legend = legend_labels,
             bty = "n", xpd = NA,
             pt.bg = legend_colors,
             pch = legend_pch,
             pt.lwd = 0.4,
             pt.cex = 1.5,
             y.intersp = 1.4,
             cex = 0.7)

      # add scale bar (automatically adjusts to plot dimensions)
      suppressMessages({
        prettymapr::addscalebar(
          plotunit = "latlon",
          plotepsg = 4326,
          widthhint = 0.20,
          unitcategory = "metric",
          htin = 0.05,
          padin = c(0.15, 0.15),
          style = "bar",
          lwd = 1,
          linecol = "black",
          label.col = "black",
          tick.cex = 0.7,
          label.cex = 0.8
        )
      })
    }


    ############################################################################
    # Save data ################################################################

    # save the processed data
    data[[i]] <- data.table::copy(dt)

    # force garbage collection after processing each dataset
    gc()
  }

  ##############################################################################
  # Return data ################################################################
  ##############################################################################

  # print final message
  cat("All done!\n")

  # print time taken
  end.time <- Sys.time()
  time.taken <- end.time - start.time
  cat(crayon::bold("Total execution time:"), sprintf("%.02f", as.numeric(time.taken)), base::units(time.taken), "\n\n")


  # return cleaned data
  return(data)

}


#######################################################################################################
#######################################################################################################
#######################################################################################################
